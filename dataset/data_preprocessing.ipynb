{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras import preprocessing\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe meme_data and drop duplicates\n",
    "df = pd.read_csv('memes_data.tsv', sep='\\t')\n",
    "df1 = df.drop_duplicates(subset=['HashId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe as long as the amount of images downloaded locally\n",
    "# total dataset is <200000, I have only downloaded 113914 memes\n",
    "df1 = df1.loc[:114517] # the dataframe index goes up to 114517 from original dataframe since we dropped duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate empty list to append all images into an numpy array\n",
    "images_as_array = []\n",
    "\n",
    "# for loop to preprocess images, changing all image sizes to 64x64 and converting to grayscale to reduce the amount of data\n",
    "for i in range(len(df1)):\n",
    "    try:\n",
    "        image = tf.keras.preprocessing.image.load_img(f'D:/lh_final_data_images/img{str(i)}.jpg', color_mode='grayscale', target_size=(64, 64))\n",
    "        input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "        images_as_array.append(input_arr)\n",
    "    except:\n",
    "        images_as_array.append(np.nan) # this is to append nan values where images did not download correctly/are corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113914"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that all images were converted to numpy array\n",
    "len(images_as_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking shape of a single numpy array image\n",
    "images_as_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the numpy array of images to dataframe\n",
    "df1['img_array'] = images_as_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AltText           0\n",
       "CaptionText       0\n",
       "ImageURL          0\n",
       "HashId            0\n",
       "MemeLabel         0\n",
       "img_array      1574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 1574 null values we got from images that were corrupted\n",
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AltText        0\n",
       "CaptionText    0\n",
       "ImageURL       0\n",
       "HashId         0\n",
       "MemeLabel      0\n",
       "img_array      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide all numbers of our numpy array by 255 to turn scale our numpy array between 0 and 1\n",
    "df1['img_array'] = df1['img_array'] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-b786d16fda66>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df1['CaptionText'] = df1.CaptionText.str.replace('[^a-zA-Z0-9]', ' ')\n"
     ]
    }
   ],
   "source": [
    "# code to keep only alphanumeric characters in the labels column\n",
    "df1['CaptionText'] = df1.CaptionText.str.replace('[^a-zA-Z0-9]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CaptionText'] = df1['CaptionText'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112340, 179)\n"
     ]
    }
   ],
   "source": [
    "# with max length=128, transform each row to a list of 128 integer values using tokenization\n",
    "maxlen = 128\n",
    "t = Tokenizer(char_level=True, lower=False)\n",
    "t.fit_on_texts(df1['CaptionText'])\n",
    "tokenized = t.texts_to_sequences(df1['CaptionText'])\n",
    "padded_names = preprocessing.sequence.pad_sequences(tokenized, maxlen=maxlen, padding='post')\n",
    "print(padded_names.shape) # print shape of text labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'E': 2, 'O': 3, 'T': 4, 'A': 5, 'I': 6, 'N': 7, 'S': 8, 'R': 9, 'e': 10, 'H': 11, 'L': 12, 'M': 13, 'D': 14, 'U': 15, 'o': 16, 'Y': 17, 't': 18, 'a': 19, 'G': 20, 'C': 21, 'n': 22, 'i': 23, 'W': 24, 's': 25, 'r': 26, 'P': 27, 'F': 28, 'B': 29, 'h': 30, 'l': 31, 'K': 32, 'u': 33, 'd': 34, 'm': 35, 'y': 36, 'V': 37, 'g': 38, 'c': 39, 'p': 40, 'w': 41, 'f': 42, 'b': 43, 'k': 44, 'v': 45, '0': 46, 'J': 47, '1': 48, 'X': 49, '2': 50, 'Z': 51, '9': 52, '5': 53, 'x': 54, '3': 55, 'Q': 56, 'j': 57, '4': 58, 'z': 59, '6': 60, '8': 61, '7': 62, 'q': 63}\n"
     ]
    }
   ],
   "source": [
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 36,  1, 35, 16, 35,  1, 41, 30, 10, 22,  1, 23,  1, 40, 31, 19,\n",
       "       36,  1, 41, 23, 18, 30,  1, 35, 36,  1, 40, 30, 16, 22, 10,  1, 42,\n",
       "       16, 26,  1, 55, 46,  1, 35, 23, 22, 33, 18, 10, 25,  1, 35, 36,  1,\n",
       "       35, 16, 35,  1, 41, 30, 10, 22,  1, 25, 30, 10,  1, 31, 16, 16, 44,\n",
       "       25,  1, 19, 18,  1, 23, 22, 25, 18, 19, 38, 26, 19, 35,  1, 40, 30,\n",
       "       16, 22, 10,  1, 42, 16, 26,  1, 18, 41, 16,  1, 30, 16, 33, 26, 25,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112340"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only label and input data into new dataframe\n",
    "df2 = df1[['CaptionText', 'img_array']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CaptionText</th>\n",
       "      <th>img_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my mom when i play with my phone for 30 minute...</td>\n",
       "      <td>[[[0.5882353], [0.59607846], [0.59607846], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doing your own research for a test Copy and pa...</td>\n",
       "      <td>[[[0.5803922], [0.5921569], [0.59607846], [0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 000 000 followers on tik tok 1 point on imgflip</td>\n",
       "      <td>[[[0.58431375], [0.5921569], [0.59607846], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making original memes Following the idea of an...</td>\n",
       "      <td>[[[0.5803922], [0.5921569], [0.59607846], [0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>[[[0.58431375], [0.5921569], [0.59607846], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114513</th>\n",
       "      <td>REALIZES SUCH A FAILURE I AM WITH ONLY 2 000 P...</td>\n",
       "      <td>[[[0.36862746], [0.44313726], [0.3529412], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114514</th>\n",
       "      <td>HERE I HEARD YOU ARE FROM NEW HAMPSHIRE</td>\n",
       "      <td>[[[0.36862746], [0.4509804], [0.3529412], [0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114515</th>\n",
       "      <td>THAT MOMENT WHEN YOUR LEAST FAVORITE CHARACTER...</td>\n",
       "      <td>[[[0.36862746], [0.4509804], [0.3529412], [0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114516</th>\n",
       "      <td>I M GONNA FOLLOW JESUS  EXAMPLE  SHOW UP TO SO...</td>\n",
       "      <td>[[[0.36862746], [0.4509804], [0.3254902], [0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114517</th>\n",
       "      <td>HAVE A GOOD WEEK EVERYONE I AM GOING TO BE SPE...</td>\n",
       "      <td>[[[0.36862746], [0.4509804], [0.3529412], [0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112340 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              CaptionText  \\\n",
       "0       my mom when i play with my phone for 30 minute...   \n",
       "1       Doing your own research for a test Copy and pa...   \n",
       "2       1 000 000 followers on tik tok 1 point on imgflip   \n",
       "3       Making original memes Following the idea of an...   \n",
       "4                                                       M   \n",
       "...                                                   ...   \n",
       "114513  REALIZES SUCH A FAILURE I AM WITH ONLY 2 000 P...   \n",
       "114514            HERE I HEARD YOU ARE FROM NEW HAMPSHIRE   \n",
       "114515  THAT MOMENT WHEN YOUR LEAST FAVORITE CHARACTER...   \n",
       "114516  I M GONNA FOLLOW JESUS  EXAMPLE  SHOW UP TO SO...   \n",
       "114517  HAVE A GOOD WEEK EVERYONE I AM GOING TO BE SPE...   \n",
       "\n",
       "                                                img_array  \n",
       "0       [[[0.5882353], [0.59607846], [0.59607846], [0....  \n",
       "1       [[[0.5803922], [0.5921569], [0.59607846], [0.6...  \n",
       "2       [[[0.58431375], [0.5921569], [0.59607846], [0....  \n",
       "3       [[[0.5803922], [0.5921569], [0.59607846], [0.6...  \n",
       "4       [[[0.58431375], [0.5921569], [0.59607846], [0....  \n",
       "...                                                   ...  \n",
       "114513  [[[0.36862746], [0.44313726], [0.3529412], [0....  \n",
       "114514  [[[0.36862746], [0.4509804], [0.3529412], [0.1...  \n",
       "114515  [[[0.36862746], [0.4509804], [0.3529412], [0.1...  \n",
       "114516  [[[0.36862746], [0.4509804], [0.3254902], [0.1...  \n",
       "114517  [[[0.36862746], [0.4509804], [0.3529412], [0.1...  \n",
       "\n",
       "[112340 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write label and input data dataframe into tsv file\n",
    "df2.to_csv('train_test_memes.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
